import os
import glob
import keras
import keras.callbacks as KC
import numpy as np
import tensorflow as tf
from keras import models as KM
from keras.optimizers import Adam
from unet import metrics
from unet import models
from unet.generators import image_seg_generator, image_seg_generator_rgb, \
    image_seg_generator_rgb_validation


def train(training_dir,
             path_label_list,
             model_dir,
             path_group_list=None,
             validation_dir=None,
             batchsize=1,
             crop_size=128,
             scaling_bounds=0.15,
             rotation_bounds=15,
             nonlinear_rotation=False,
             max_noise_std=0.1,
             max_noise_std_fa=0.03,
             gamma_std=0.1,
             contrast_std=0.1,
             brightness_std=0.1,
             randomize_resolution=False,
             generator_mode='rgb',
             diffusion_resolution=None,
             speckle_frac_selected=1e-4,
             seg_selection='grouped',
             flag_deformation=True,
             deformation_max=5.0,
             n_levels=5,
             nb_conv_per_level=2,
             conv_size=3,
             unet_feat_count=24,
             feat_multiplier=2,
             dropout=0,
             activation='elu',
             lr=1e-4,
             lr_decay=0,
             wl2_epochs=5,
             dice_epochs=200,
             steps_per_epoch=1000,
             checkpoint=None,
             checkpoint_l2=None,
             checkpoint_dice=None,
             dice_version="grouped",
             checkpoint_frequency=1):

    # check epochs
    assert (wl2_epochs > 0) | (dice_epochs > 0), \
        'either wl2_epochs or dice_epochs must be positive, had {0} and {1}'.format(wl2_epochs, dice_epochs)
    # check generator mode
    assert (generator_mode == 'fa_v1') | (generator_mode == 'rgb'), \
        'generator mode must be fa_v1 or rgb'

    assert (dice_version == "grouped") | (dice_version == "individual"), \
        'dice version must be grouped or individual'

    if diffusion_resolution is not None:
        if type(diffusion_resolution) == int:
            diffusion_resolution = [diffusion_resolution] * 3

    if checkpoint is None :
        if (checkpoint_dice is None) & (checkpoint_l2 is None):
            checkpoint_list=sorted(glob.glob(model_dir + '/dice_???.h5'))
            if len(checkpoint_list)!=0 :
                checkpoint_dice = checkpoint_list[-1]
            else :
                checkpoint_list=sorted(glob.glob(model_dir + '/wl2_???.h5'))
                if len(checkpoint_list)!=0 :
                    checkpoint_l2 = checkpoint_list[-1]

        if checkpoint_l2 is not None:
            checkpoint = checkpoint_l2


    if generator_mode == 'rgb':
        generator = image_seg_generator_rgb(training_dir,
                                path_label_list,
                                path_group_list,
                                batchsize=batchsize,
                                scaling_bounds=scaling_bounds,
                                rotation_bounds=rotation_bounds,
                                nonlinear_rotation=nonlinear_rotation,
                                max_noise_std=max_noise_std,
                                max_noise_std_fa=max_noise_std_fa,
                                gamma_std=gamma_std,
                                contrast_std=contrast_std,
                                brightness_std=brightness_std,
                                crop_size=crop_size,
                                randomize_resolution=randomize_resolution,
                                diffusion_resolution=diffusion_resolution,
                                speckle_frac_selected=speckle_frac_selected,
                                seg_selection=seg_selection,
                                flag_deformation=flag_deformation,
                                deformation_max=deformation_max)
    else:
        generator = image_seg_generator(training_dir,
                                path_label_list,
                                batchsize=batchsize,
                                scaling_bounds=scaling_bounds,
                                rotation_bounds=rotation_bounds,
                                max_noise_std=max_noise_std,
                                max_noise_std_fa=max_noise_std_fa,
                                gamma_std=gamma_std,
                                contrast_std=contrast_std,
                                brightness_std=brightness_std,
                                crop_size=crop_size,
                                randomize_resolution=randomize_resolution,
                                diffusion_resolution=diffusion_resolution)

    label_list = np.sort(np.load(path_label_list)).astype(int)
    n_labels = np.size(label_list)

    if validation_dir is not None:
        validation_generator = image_seg_generator_rgb_validation(validation_dir,
                                path_label_list,
                                batchsize=batchsize,
                                scaling_bounds=scaling_bounds,
                                rotation_bounds=rotation_bounds,
                                max_noise_std=max_noise_std,
                                max_noise_std_fa=max_noise_std_fa,
                                gamma_std=gamma_std,
                                contrast_std=contrast_std,
                                brightness_std=brightness_std,
                                crop_size=crop_size,
                                randomize_resolution=randomize_resolution,
                                diffusion_resolution=diffusion_resolution)
    else:
        validation_generator = None

    if path_group_list is not None:
        group_seg = np.load(path_group_list)
        n_groups = group_seg.max() + 1
    else:
        group_seg = None
        n_groups = None


    if crop_size is None:
        aux = next(generator)
        crop_size = aux[0].shape[1:-1]
    if type(crop_size) == int:
        crop_size = [crop_size] * 3

    unet_input_shape = [*crop_size, 5]

    unet_model = models.unet(nb_features=unet_feat_count,
                                 input_shape=unet_input_shape,
                                 nb_levels=n_levels,
                                 conv_size=conv_size,
                                 nb_labels=n_labels,
                                 feat_mult=feat_multiplier,
                                 nb_conv_per_level=nb_conv_per_level,
                                 conv_dropout=dropout,
                                 batch_norm=-1,
                                 activation=activation,
                                 input_model=None)

    # pre-training with weighted L2, input is fit to the softmax rather than the probabilities
    if (wl2_epochs > 0) & (checkpoint_dice is None):
        wl2_model = models.Model(unet_model.inputs, [unet_model.get_layer('unet_likelihood').output])
        train_model(wl2_model, generator, lr, lr_decay, wl2_epochs, steps_per_epoch, model_dir, 'wl2', n_labels, checkpoint)
        checkpoint_dice = os.path.join(model_dir, 'wl2_%03d.h5' % wl2_epochs)

    # fine-tuning with dice metric
    train_model(unet_model, generator, lr, lr_decay, dice_epochs, steps_per_epoch, model_dir, 'dice', n_labels,
                group_seg, n_groups, checkpoint_dice, validation_generator=validation_generator, dice_version=dice_version,
                checkpoint_frequency=checkpoint_frequency)

    print('All done!')


def train_model(model,
                generator,
                learning_rate,
                lr_decay,
                n_epochs,
                n_steps,
                model_dir,
                metric_type,
                n_labels,
                group_seg=None,
                n_groups=None,
                path_checkpoint=None,
                validation_generator=None,
                dice_version="grouped",
                checkpoint_frequency=1,
                reinitialise_momentum=False):

    # prepare log folder
    log_dir = os.path.join(model_dir, 'logs')
    if os.path.exists(model_dir) is False:
        os.mkdir(model_dir)
    if os.path.exists(log_dir) is False:
        os.mkdir(log_dir)

    # model saving callback
    save_file_name = os.path.join(model_dir, '%s_{epoch:03d}.h5' % metric_type)
    callbacks = [KC.ModelCheckpoint(save_file_name, verbose=1, period=checkpoint_frequency)]

    # TensorBoard callback
    if metric_type == 'dice':
        callbacks.append(KC.TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=False))

    compile_model = True
    init_epoch = 0
    if path_checkpoint is not None:
        print('Checkpoint found:')
        print(path_checkpoint)
        if metric_type in path_checkpoint:
            init_epoch = int(os.path.basename(path_checkpoint).split(metric_type)[1][1:-3])
        if (not reinitialise_momentum) & (metric_type in path_checkpoint):
            if metric_type == 'dice':
                if dice_version == "grouped":
                    custom_objects = {'tf': tf, 'keras': keras, 'loss': metrics.DiceLossGrouped(group_seg, n_groups).loss}
                else :
                    custom_objects = {'tf': tf, 'keras': keras, 'loss': metrics.DiceLoss().loss}
            else :
                custom_objects = {'tf': tf, 'keras': keras, 'loss': metrics.WL2Loss(3.0, n_labels, background_weight=0.01).loss}
            model = KM.load_model(path_checkpoint, custom_objects=custom_objects)
            compile_model = False
        else:
            model.load_weights(path_checkpoint, by_name=True)


    # compile
    if compile_model :
        if metric_type == 'dice':
            if dice_version=="grouped":
                assert (group_seg is not None) & (n_groups is not None), \
                    "grouped Dice requires thalamic nuclei be grouped in a file provided by group_seg"

                model.compile(optimizer=Adam(lr=learning_rate, decay=lr_decay),
                          loss=metrics.DiceLossGrouped(group_seg, n_groups).loss,
                          loss_weights=[1.0])

            else:
                model.compile(optimizer=Adam(lr=learning_rate, decay=lr_decay),
                              loss=metrics.DiceLoss().loss,
                              loss_weights=[1.0])
        else:
            model.compile(optimizer=Adam(lr=learning_rate, decay=lr_decay),
                          loss=metrics.WL2Loss(3.0, n_labels, background_weight=0.01).loss, # since we crop, 0.01 is ok
                          loss_weights=[1.0])

    # fit
    if validation_generator is not None:
        validation_freq = list(range(1,6))

        for il in range(10, n_epochs, 5):
            validation_freq.append(il)

        validation_freq.append(n_epochs)

        model.fit_generator(generator,
                            epochs=n_epochs,
                            steps_per_epoch=n_steps,
                            callbacks=callbacks,
                            initial_epoch=init_epoch,
                            use_multiprocessing=True,
                            validation_data=validation_generator,
                            validation_steps=60,
                            validation_freq=validation_freq)
    else:
        model.fit_generator(generator,
                            epochs=n_epochs,
                            steps_per_epoch=n_steps,
                            callbacks=callbacks,
                            initial_epoch=init_epoch,
                            use_multiprocessing=True)
